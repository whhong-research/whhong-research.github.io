[{"content":"主要贡献 回答了两个基本问题：\n风场中的SCADA系统是否是专门设计的状态监测系统（CMS）的可行替代方案； 结合CMS和运维策略以最大限度提到OWT的财务效益的最佳方法是什么； 基本假设 每个子系统的健康状态分为四类：正常、轻微故障、严重故障和失效；\n轻微故障或严重故障时，子系统仍允许运行；\n严重故障更容易被CMS所监测到；\n不同部件在故障发展的不同阶段有不同的误报率；\n任何子系统失效都将触发风机停机；\n每个子系统的退化过程遵循威布尔分布；\n威布尔分布的参数来源于文献中公开的故障率数据；\n风机使用寿命为20年；\n假设修复后组件的情况“as good as new”\n运维策略 纠正性维护 定义：在子结构发生完全失效（failure）后进行； 周期性维护 定义：按照预先确定的时间间隔进行维护； 将周期性维护分为大修和小修，基本服务（BS）是发现并修复那些常见、易于修复但难以监控的问题；高级服务（AS）将对所有结构部件进行检查； 基于状态的维护 定义： 基于风机实际的健康状态进行维护； 有效程度取决于CMS的故障检测能力； 维护框架 Maintenance 1对应修复Minor faults; Maintenance 2对应修复critical faults; Maintenance 3对应修复failures; 运维策略指定 五种不同的运维策略\n四种不同的monitoring system：\n没有部署monitoring system; SCADA CMS SCADA+CMS 退化模型 系统退化模型架构：\n检测模型 The purpose-designed CMS (特意安装传感器用于监测某一组件的健康状态) 整体框架如下：\n硬件健康状态的模拟（即考虑传感器失效概率）：C1表示传感器检测到系统故障的概率，C2表示传感器损坏的概率；\n考虑数据采集系统（DAQ）发生故障的可能性：\n监测系统发出故障预警信号，对应的故障类型概率：其中normal : minor fault : critical fault为0.4，0.5，0.1\nSCADA-based CMS 故障检测概率（Probability of detection），文中直接通过假设得出 修复模型 维护成本 维护流程 M1代表从检测到故障到发出修复指令的时间； M2代表安排会议来指定维修计划的时间； M3代表制定计划的时间； M4+M5代表了租用船只，调遣人员，准备维护设备的时间； M6代表了如果有备件，那么将启用M6，这个时间远短于M5； M7没啥意思，表示维护船准备出发； M8和M9代表运输船到达现场的时间，M9考虑了天气因素的影响，即等待合适窗口时间； M11代表了维护所需要的时间； 仿真流程 风机的服役过程 小结 对所有的随机变量进行采样，生成参数； 对一个风机执行上述所有流程，直至达到服务寿命； 反复迭代直至收敛 （30000次后收敛至稳定值，所有模拟均进行了50000次迭代；） 结果及考虑的指标 使用率 缩短相邻的AS能提高风机的使用率，但仍然不如使用任何一种monitoring system的情况； 当频繁进行AS时，结合两个monitoring system可能会导致使用率下降，因为检测到损伤后对风机进行修复的停机时间变长； COA (the ratio of maintenance cost to availability) ","date":"2025-03-03T00:00:00Z","image":"https://whhong-research.github.io/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB2-impact-of-condition-monitoring-on-the-maintenance-and-economic-viability-of-offshore-wind-turbines/1_hu_d016efb09b765092.png","permalink":"https://whhong-research.github.io/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB2-impact-of-condition-monitoring-on-the-maintenance-and-economic-viability-of-offshore-wind-turbines/","title":"论文阅读（2）: Impact of condition monitoring on the maintenance and economic viability of offshore wind turbines"},{"content":"参考文献 Jonkman, J.M., Hayman, G.J., Jonkman, B.J., Damiani, R.R., Murray, R.E., n.d. AeroDyn v15 User’s Guide and Theory Manual. Renewable Energy. Openfast帮助文档：https://openfast.readthedocs.io/en/main/index.html AeroDyn 简介 Aerodyn是一个时域的风机空气动力学模块，可以作为代码单独驱动以计算未跟openfast耦合的风机的空气动力响应； Aerodyn用于计算叶片和塔筒的空气动力荷载，计算原理遵循致动线理论（the principles of actuator lines）； Aerodyn由6个子模型组成，分别是： rotor wake/induction blade airfoil aerodynamics tower influence on the fluid local to the blade nodes tower and nacelle drag aeroacoustics buoyancy on the blade, hub, nacelle and tower 输入文件 基本单位：（kg, m, s, N） General options DTAero: 空气动力学的计算步骤，建议最少设置200步；\nWake_mod:\n设置为0说明不考虑 induced velocities； 设置为1将基于BEM理论考虑这些效果； 设置为3将使用 free vortex wake model，注意在线性分析阶段不能设置为3； Twrpotent:\n设置为0说明不考虑塔筒对叶片局部流场的潜在影响； 设置为1说明适用standard potential-flow model； 设置为2说明还考虑了Bak修正； 建模参数建议 NumVBlNds: 建议设置在10-20之间，用于平衡计算精度和计算成本 模拟运行中的风机叶片时： 建议包括动态BEM模型（Wake_Mod = 1）和UA（AFAeroMod = 2）； 启用 SkewMod = 2，TipLoss = TRUE，HubLoss = TRUE，TanInd = TRUE； 然而当偏航误差大于45度时，应用SkewMod = 2是无效的； BEM的非线性求解与入流角相关，IndToler建议设置为DEFAULT； 输出设置 AeroDyn能够输出沿塔筒的9个节点和沿叶片的9个节点中输出气动力学和运动学量；\nBldNd_BladesOut: 表示要输出的叶片数量；\nBldNd_BlOutNd：表示要输出的节点\n考虑输出叶片各节点的气动力：\n”to plane“：表示相对于转子平面，Fx表示垂直于叶片旋转平面的力，Fy表示平行于叶片旋转平面的力。适用于整体叶片性能和计算全局荷载；\n”to chord“: 表示相对叶片弦线，代表局部/微观的参考系，Fn是垂直于叶片局部弦线的力，Ft是平行于叶片局部弦线的力，沿着前缘到后缘的方向，影响叶片的扭转变形。适用于局部叶片的结构响应和变形。\n1 2 3 4 5 \u0026#34;Mm\u0026#34; - Pitching moment per unit length at each node \u0026#34;Fx\u0026#34; - Normal force (to plane) per unit length at each node \u0026#34;Fy\u0026#34; - Tangential force (to plane) per unit length at each node \u0026#34;Fn\u0026#34; - Normal force (to chord) per unit length at each node \u0026#34;Ft\u0026#34; - Tangential force (to chord) per unit length at each node 输出文件变量设置：\nOutList: 注意使用节点编号时，节点编号范围为1-9，举例来说，若输入B1N10Fx会发出报错；如果想输出叶片中编号为10的截面的信息，需要输入节点编号10所对应的位置；如下图所示；\n1 10,11,12,13,14,15,16,17,18 BlOutNd - Blade nodes whose values will be output (-) 叶片中的10号截面对应的Output node为1，输出的B1N1Fx代表的是叶片1的10号截面的平行于旋转平面的力\n输出文件 摘要文件 （Summary file） 当SumPrint设置为TRUE时，会生成文件OutFileRoot.AD.sum来总结相关空气动力学模型的关键信息，包括启用的功能和输出； 结果文件（Results files） 生成OutFileRoot.#.out文件； 数据通道在初始的input file中进行定义； 测试案例 输入文件示例 修改AeroDyn的输入文件（通常该文件后缀为”AeroDyn15.dat“）中的输出模块\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 ====== Outputs ==================================================================================== True SumPrint - Generate a summary file listing input options and interpolated properties to \u0026#34;\u0026lt;rootname\u0026gt;.AD.sum\u0026#34;? (flag) 9 NBlOuts - Number of blade node outputs [0 - 9] (-) 1,2,3,4,5,6,7,8,9 BlOutNd - Blade nodes whose values will be output (-) 0 NTwOuts - Number of tower node outputs [0 - 9] (-) TwOutNd - Tower nodes whose values will be output (-) OutList - The next line(s) contains a list of output parameters. See OutListParameters.xlsx for a listing of available output channels, (-) \u0026#34;B1N1Fn,B1N1Ft,B1N1Mm\u0026#34; \u0026#34;B1N2Fn,B1N2Ft,B1N2Mm\u0026#34; \u0026#34;B1N3Fn,B1N3Ft,B1N3Mm\u0026#34; \u0026#34;B1N4Fn,B1N4Ft,B1N4Mm\u0026#34; \u0026#34;B1N5Fn,B1N5Ft,B1N5Mm\u0026#34; \u0026#34;B1N6Fn,B1N6Ft,B1N6Mm\u0026#34; \u0026#34;B1N7Fn,B1N7Ft,B1N7Mm\u0026#34; \u0026#34;B1N8Fn,B1N8Ft,B1N8Mm\u0026#34; \u0026#34;B1N9Fn,B1N9Ft,B1N9Mm\u0026#34; \u0026#34;B2N1Fn,B2N1Ft,B2N1Mm\u0026#34; \u0026#34;B2N2Fn,B2N2Ft,B2N2Mm\u0026#34; \u0026#34;B2N3Fn,B2N3Ft,B2N3Mm\u0026#34; \u0026#34;B2N4Fn,B2N4Ft,B2N4Mm\u0026#34; \u0026#34;B2N5Fn,B2N5Ft,B2N5Mm\u0026#34; \u0026#34;B2N6Fn,B2N6Ft,B2N6Mm\u0026#34; \u0026#34;B2N7Fn,B2N7Ft,B2N7Mm\u0026#34; \u0026#34;B2N8Fn,B2N8Ft,B2N8Mm\u0026#34; \u0026#34;B2N9Fn,B2N9Ft,B2N9Mm\u0026#34; END of input file (the word \u0026#34;END\u0026#34; must appear in the first 3 columns of this last OutList line) --------------------------------------------------------------------------------------- 输出文件示例 从”.AD.sum“文件中可以看到本次输出的变量\n从\u0026quot;.out\u0026quot;文件中，能够看到输出结果\nPython脚本批量化处理 实现功能1：批量化修改Aerodyn的输入文件，并修改对应的fst文件；\n实现功能2：批量化读取Aerodyn的输出文件，提取并保存Aerodyn中定义的输出变量到excel表格中；\n输入参数：\nall_nodes = list(range(1, 20)) 定义需要的节点数量，此处为19个节点；\n设置文件路径\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 import os import subprocess import pandas as pd import time from openfast_toolbox.io import FASTInputFile, FASTOutputFile def split_nodes_into_groups(nodes, group_size=9): \u0026#34;\u0026#34;\u0026#34;将节点列表分成每组最多9个节点\u0026#34;\u0026#34;\u0026#34; return [nodes[i:i + group_size] for i in range(0, len(nodes), group_size)] def modify_aerodyn(aero_file_path, node_group, output_path): \u0026#34;\u0026#34;\u0026#34;修改AeroDyn输入文件\u0026#34;\u0026#34;\u0026#34; f = FASTInputFile(aero_file_path) # 设置输出节点数量 num_nodes = len(node_group) f[\u0026#39;NBlOuts\u0026#39;] = num_nodes # 设置输出节点数量 # 设置节点 f[\u0026#39;BlOutNd\u0026#39;] = \u0026#39;,\u0026#39;.join(map(str, node_group)) # 生成输出列表 output_list = [\u0026#34;\u0026#34;] # 添加初始换行 for blade in [1, 2, 3]: for node_index, node_value in enumerate(node_group, 1): # 从1开始计数 output_list.extend([ f\u0026#34;B{blade}N{node_index}Fn\u0026#34;, f\u0026#34;B{blade}N{node_index}Ft\u0026#34;, f\u0026#34;B{blade}N{node_index}Mm\u0026#34; ]) f[\u0026#39;OutList\u0026#39;] = output_list f.write(output_path) return output_path def run_openfast(fast_exe_path, fst_file_path): \u0026#34;\u0026#34;\u0026#34;运行OpenFAST\u0026#34;\u0026#34;\u0026#34; try: working_dir = os.path.dirname(fst_file_path) os.chdir(working_dir) command = [fast_exe_path, os.path.basename(fst_file_path)] subprocess.run(command, check=True) print(\u0026#34;OpenFAST simulation completed successfully\u0026#34;) return True except subprocess.CalledProcessError as e: print(f\u0026#34;Error running OpenFAST: {e}\u0026#34;) return False def extract_blade_data(outb_file, node_group): \u0026#34;\u0026#34;\u0026#34;从.outb文件提取数据\u0026#34;\u0026#34;\u0026#34; df = FASTOutputFile(outb_file).toDataFrame() blade_data = {1: {}, 2: {}, 3: {}} time = df[\u0026#39;Time_[s]\u0026#39;] for blade in [1, 2, 3]: data_dict = {\u0026#39;Time_[s]\u0026#39;: time} # 枚举node_group获取索引和值 for node_index, node_value in enumerate(node_group, 1): # 从1开始计数 for measure in [\u0026#39;Fn\u0026#39;, \u0026#39;Ft\u0026#39;, \u0026#39;Mm\u0026#39;]: if measure == \u0026#39;Mm\u0026#39;: col_name = f\u0026#39;B{blade}N{node_index}{measure}_[N-m/m]\u0026#39; else: # measure is \u0026#39;Fn\u0026#39; or \u0026#39;Ft\u0026#39; col_name = f\u0026#39;B{blade}N{node_index}{measure}_[N/m]\u0026#39; if col_name in df.columns: data_dict[f\u0026#39;Node{node_value}_{measure}\u0026#39;] = df[col_name] print(f\u0026#34;Found data for {col_name}\u0026#34;) else: print(f\u0026#34;Column {col_name} not found\u0026#34;) blade_data[blade] = pd.DataFrame(data_dict) return blade_data def merge_blade_data(all_runs_data): \u0026#34;\u0026#34;\u0026#34;合并多次运行的数据\u0026#34;\u0026#34;\u0026#34; merged_data = {1: {}, 2: {}, 3: {}} for blade in [1, 2, 3]: # 使用第一次运行的时间数据 merged_df = pd.DataFrame({\u0026#39;Time_[s]\u0026#39;: all_runs_data[0][blade][\u0026#39;Time_[s]\u0026#39;]}) # 合并所有运行的数据 for run_data in all_runs_data: cols_to_merge = [col for col in run_data[blade].columns if col != \u0026#39;Time_[s]\u0026#39;] merged_df[cols_to_merge] = run_data[blade][cols_to_merge] merged_data[blade] = merged_df return merged_data def save_to_excel(blade_data, output_path): \u0026#34;\u0026#34;\u0026#34;保存数据到Excel文件\u0026#34;\u0026#34;\u0026#34; with pd.ExcelWriter(output_path) as writer: for blade_num, data in blade_data.items(): data.to_excel(writer, sheet_name=f\u0026#39;Blade_{blade_num}\u0026#39;, index=False) print(f\u0026#34;Data saved to {output_path}\u0026#34;) def main(): # 设置路径 work_dir = \u0026#39;E:/Study/openfast/r-test-3.5.3/glue-codes/openfast/5MW_Test_Weihao\u0026#39; fast_exe_path = \u0026#39;E:/Study/openfast/r-test-3.5.3/glue-codes/openfast/5MW_Test_Weihao/openfast_x64.exe\u0026#39; fst_file = os.path.join(work_dir, \u0026#39;5MW_Land_BD_DLL_WTurb.fst\u0026#39;) aero_file = os.path.join(work_dir, \u0026#39;NRELOffshrBsline5MW_Onshore_AeroDyn15.dat\u0026#39;) output_excel = os.path.join(work_dir, \u0026#39;blade_data_all_nodes.xlsx\u0026#39;) # 定义所有需要的节点 all_nodes = list(range(1, 20)) node_groups = split_nodes_into_groups(all_nodes) all_runs_data = [] for i, node_group in enumerate(node_groups): print(f\u0026#34;\\nProcessing node group {i + 1}: {node_group}\u0026#34;) # 修改后的气动文件名 modified_aero_file = os.path.join(work_dir, f\u0026#39;NRELOffshrBsline5MW_Onshore_AeroDyn15_group_{i + 1}.dat\u0026#39;) # 修改气动文件 modify_aerodyn(aero_file, node_group, modified_aero_file) # 修改FST文件中的AeroDyn文件路径 fst = FASTInputFile(fst_file) fst[\u0026#39;AeroFile\u0026#39;] = f\u0026#39;\u0026#34;{os.path.basename(modified_aero_file)}\u0026#34;\u0026#39; modified_fst_file = os.path.join(work_dir, f\u0026#39;5MW_Land_DLL_WTurb_group_{i + 1}.fst\u0026#39;) fst.write(modified_fst_file) # 运行OpenFAST if run_openfast(fast_exe_path, modified_fst_file): # 提取数据 outb_file = os.path.join(work_dir, f\u0026#39;5MW_Land_DLL_WTurb_group_{i + 1}.outb\u0026#39;) run_data = extract_blade_data(outb_file, node_group) all_runs_data.append(run_data) # 等待一小段时间确保文件写入完成 time.sleep(1) # 合并所有运行的数据 if all_runs_data: merged_data = merge_blade_data(all_runs_data) # 保存最终数据 save_to_excel(merged_data, output_excel) else: print(\u0026#34;No data was collected from any runs\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() 避坑点1：Outlist需要添加初始换行，否则第一个变量将不会输出； 避坑点2：\u0026lsquo;BlOutNd\u0026rsquo;需要使用“,”来连接变量，直接赋值会导致出现\u0026quot;()\u0026quot;，造成报错； ","date":"2025-02-26T00:00:00Z","image":"https://whhong-research.github.io/p/openfast%E4%BB%BF%E7%9C%9F1aerodyn%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/1_hu_34bb04d9ac620d6c.jpg","permalink":"https://whhong-research.github.io/p/openfast%E4%BB%BF%E7%9C%9F1aerodyn%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","title":"OpenFast仿真（1）：AeroDyn使用指南"},{"content":"报告简介 基本信息 项目名称：PSA study Structural health monitoring of offshore structure by use of sensor data\n发布时间：2024-02-21\n项目目标：\n探讨SHM如何作为一种评估海上结构健康的决策支持工具； 如何利用SHM（传感器数据，结构故障历史记录等）指导运维； 评估对比不同的SHM方法的优劣势； 介绍一些使用SHM进行维护计划的海上结构案例； “This report explores structural health monitoring (SHM) as a decision support tool to assess the structural health of offshore structures. The main objective of this report is to evaluate how SHM may be used to improve safety and inspection and maintenance planning with use of sensor data and structural failure history. The report evaluates different SHM approaches, including strengths and weaknesses, and contains some examples of use of SHM for both maintenance planning and to capture safety critical behavior of offshore structures.”\n关键名词定义 SHM：一种能用于检测结构性故障的诊断工具，可能还包括警告、定位和评估结构性故障后果等功能；\n“SHM is a diagnostic tool that has the objective to detect a structural failure, and may in addition warn, localize and evaluate the consequence of a structural failure.”\nDigital twin：数字孪生是一种系统或资产的虚拟表示，使得用户能够使用该系统或资产的信息，集成模型和数据，其目的是为用户提供全生命周期的决策支持；\n“A digital twin is a virtual representation of a system or asset that calculates system states and makes system information available, through integrated models and data, with the purpose of providing decision support over its life cycle.”\nInspection：检查、测量或测试的过程，以确定结构当前的状况；\n“process of examination, measurement and/or testing to determine a condition or state of an item”\nVirtual sensors: 虚拟传感器是数值传感器或是基于物理传感器派生的传感器；\n“virtual sensors are numerical sensors or derived based on physical sensors”\nMonitoring system：监测系统通过测量设备（传感器）接受有关系统的信息；\n\u0026ldquo;a monitoring system receives information about the system through measuring devices (sensors), and makes it available to the operator\u0026rdquo;\nRisk-based inspection：基于风险的检验（Risk-Based Inspection, RBI）是一个识别、评估和映射工业风险（由腐蚀和应力开裂引起）的过程，这些风险可能会影响压力设备和结构构件的完整性。RBI主要针对可以通过适当的检验和分析来控制的风险。在RBI过程中，工程师设计检验策略（检验什么、何时检验、如何检验），以最有效地匹配预测或观察到的劣化机理。\n“risk-based inspection (RBI) is a process that identifies, assesses and maps industrial risks (due to corrosion and stress cracking), which could compromise equipment integrity in both pressurized equipment and structural elements. RBI addresses risks that can be controlled through proper inspections and analysis. During the RBI process, engineers design inspection strategies (what, when, how to inspect) that most efficiently match forecasted or observed degradation mechanisms.”\n结构健康监测（SHM） 健康监测系统的常见组件如下图所示：\nSHM系统的类别 根据输入进行划分： 划分为Sensors，Indicators，Numerical twin，Hybrid twin以及Data-Driven models； 根据功能进行划分： Level 1: 定性 (Detection) ，表明结构中可能存在损伤； Level 2: 定位 (Localization) ，提供故障的位置信息； Level 3: 定量 (Assessment) ，提供故障的大小信息； Level 4: 评估 (Consequence) ，提供故障对实际结构安全性的影响； 诊断预警 (Prognostic)：结构在不久的将来会发生损伤； Fit for purpose: 能够验证结构的强度是否足够 SHM系统流程 评估结构运营环境： 识别结构性故障模式，结构退化机制及后果； 选择合适的传感器，安装方案和成本； 构建SHM系统： 传感器安装，校准及日志系统配置； 系统集成测试； 数据记录，过滤，压缩及传输 数据分析处理： 故障诊断，损伤识别等； 模态分析 结构整体性评估 结构状态评估； 剩余寿命预测； SHM系统价值 参考文献： PSA: Svendsen et al., 2021, The use of digital solutions and structural health monitoring for integrity management of offshore structures, Rambøll report no. REN2021N00099-RAM-RP-00004 dated 14th February 2022\n引入SHM系统的主要目的是减少不确定性； 同时SHM系统还能够提供用于优化检查计划的其他信息 表1：使用SHM系统为海上结构创造的价值\nCAPEX（资本支出） OPEX（运营支出） 实际设计验证 实际安全性和风险评估 设计基础和优化 预测性维护 实施新的学习/知识差距 意外事件 - 即时信息 最小化停机时间 变化（损伤）检测 捕捉意外行为 根本原因分析 生命周期历史 预警系统 决策制定 使用SHM是否可以预防重大事故？ 挪威最大的工业事故是1981年Alexander Kjelland platform倾覆，该平台的结构性损伤起源与一个6 mm的圆角焊缝，随后支撑结构发生疲劳裂缝，导致平台一条支腿失效。\n使用基于传感器数据的SHM系统可能无法阻止该次事故，因为该平台是一个非冗余结构；\nSHM可以支持决策，减少事故发生的可能性；\n对于Alexander Kjelland事故而言，必须在裂缝发展成为致命损伤前发现它才能够阻止事故的发生；\n但该裂缝的位置并不是设计阶段评估的关键部分，通常而言传感器不会布置在该处；\n只有将裂缝布置在浮筒上，设计传感器系统能够监测到100mm的裂缝，并认识到该裂缝未来将发展成为致命损伤，才能阻止该事故；\n2009年在挪威Ekofisk 2/4 W platform船撞事故：\nSHM能够作为一种决策工具用于评估结构损伤，在进行更细致的检查之前； SHM能够提供实时的结构承载力评估和剩余寿命等（例如是否能够安排人员进入发生船撞后的结构进行检查） 然而，实现上述两点需要SHM系统能够监测到由于船撞引发的大变形； 结构完整性管理（Strucutral integrity management） SIM介绍 结构全生命周期\n定义：SIM是一个连续的过程，用于展示海上结构从安装到退役全生命周期的情况。SIM为结构的检查计划、维护及维修计划提供了一个框架，如下图所示：\n该框架中主要包含以下四个模块：\n数据和信息收集；\n结构状态评估；\n评估并选择维护策略；\n建立检查计划；\n屏障管理 （Barrier management） 参考文献： PSA, 2013, Principles for barrier management in the petroleum industry, dated 29th of January 2013\n屏障：旨在单独或共同减少特定错误、危险或事故发生的可能性，或限制其危害/不利影响的技术、操作和组织要素。 屏障要素：实现屏障功能的技术、操作或组织措施或解决方案。 屏障功能：在从故障、危险或意外情况导致事故的事件链中，屏障所承担的任务或角色。 性能影响因素：对屏障功能和要素按预期运行具有重要影响的条件。 什么是检测计划 （Inspection） 首要目标是确定：what, when, where and how to inspect\n上图还展示了population-based SHM是如何作为SIM中的一部分，黄色的风机是风场中的代表，通常是风场中使用率最高或负载最大的结构，通过采集该结构的结构信息，能够用于指导其他风机的资产管理。\n选择检测技术需要考虑该技术的检测概率，PoD (Probability of detection) 可以用来衡量检测技术的准确性。Trueness 和 Precision可以用来衡量一种检测技术的准确性。 Trueness指的的是测量结果和真实值的偏差程度；Precision指的是独立检测结果的一致性，如下图所示：\n对于分类模型，可以用混淆矩阵，AUC，召回率，分类器精度，F1得分等指标进行衡量；\nWhen to inspect: 何时进行检测应当基于TBI和CBI的组合，TBI应当根据RBI的结果来设定，随着对SHM系统信息的增加，TBI可以逐步被CBI所取代；\n数据驱动的检测计划 (Data driven inspection planning) 根据规范Norsok N-005，检测计划应考虑基于风险的检测分析结果；\nRisk based inspection (RBI)可以基于以下三点开展\n基于通用设计基准：使用同一类型或类似结构的历史数据或工程经验，检测范围通常是针对运营使用的保守假设； 基于定性分析：结合相同或类似结构的历史数据或工程经验，以及具体的设计细节，检测范围将更有针对性地集中在高利用率的特殊区域； 基于定量分析：基于特定设计的概率分析 下图展示了RBI是如何作为选择TBI或者CBI作为检测计划的基础\nCalendar-based inspection vs conditional-based inspection:\n常见海上结构故障 结构极限状态 SLS（Serviceability Limit State，正常使用极限状态）： 定义：结构在正常使用条件下应满足的功能要求，确保其在使用期间不会出现影响功能或舒适性的问题。 关注点：变形、振动、裂缝宽度等。 目标：保证结构在正常使用中的功能性和舒适性。 FLS（Fatigue Limit State，疲劳极限状态）： 定义：结构在反复荷载作用下抵抗疲劳破坏的能力。 关注点：循环应力、疲劳寿命、裂纹扩展等。 目标：防止结构因反复荷载导致的疲劳破坏。 ULS（Ultimate Limit State，承载能力极限状态）： 定义：结构在最大荷载作用下抵抗破坏的能力，涉及安全性。 关注点：强度、稳定性、整体稳定性等。 目标：确保结构在极端条件下的安全性，防止倒塌或严重破坏。 ALS（Accidental Limit State，偶然作用极限状态）： 定义：结构在偶然事件（如爆炸、撞击、火灾等）下的性能。 关注点：剩余承载力、整体稳定性、局部破坏等。 目标：保证结构在偶然事件中不发生灾难性破坏，尽量减少损失。 结构失效场景 表2 不同失效场景概述\n场景编号 场景描述 1 低周和高周疲劳导致的疲劳开裂 2 HISC（Hydrogen Induced Stress Cracking）相关开裂 3 点蚀和腐蚀 4 甲板上的掉落物 6 极端载荷导致的屈服超载 7 极端载荷导致的局部和整体屈曲 8 极端载荷导致的整体崩塌 9 局部波浪冲击导致的凹痕 10 系泊缆或拉索断裂 11 泄漏导致的进水 12 异常环境条件的影响（甲板上的波浪） 13 爆炸 下图中可以看出，疲劳、腐蚀、过载和振动是漂浮式结构中主要的故障原因，而固定式结构还包括基础与海床的相互作用以及平台间的连接桥。同时，还考虑了掉落物体以及船撞的因素。表3是根据下图进行总结得到的。\n表3：重要失效模式\n失效模式编号 描述 1 由于疲劳和腐蚀导致的（贯穿厚度）开裂 2 由于疲劳或腐蚀导致的构件分离 3 由于疲劳或腐蚀导致的构件缺失 4 由于船舶撞击或掉落物导致的凹痕和变形 5 固定式安装的灌浆连接（滑移和失效） 6 固定式安装的超载（沉降和下沉） 7 固定式安装的冲刷 8 多种原因导致的过度/意外振动 9 多种原因导致的桥梁支承问题（互连桥） 10 由风、波浪或水流作用导致的涡激振动问题 钢结构常见故障模式 钢结构通常的故障模式是结构承载力的下降，造成承载力下降的故障机制包括：材料退化、材料损失、疲劳和过度负载等。导致这些故障机制的常见影响因素如下图所示：\n海上结构故障报告 下表中总结了过去几年中主要的海上结构管理机构对重大结构性事故的报告。从下表中可以看出，欧盟仅报告了INA平台丢失的一次重大事故。\n表4：过去五年被定义为重大事故的报告事件\n地区 报告的事件 欧盟：海上油气作业安全（europa.eu） 报告的结构完整性损失事件。数据为2016年(0)、2017年(0)、2018年(0)、2019年(2起-无法确定具体事件)、2020年(1起-克罗地亚平台完全损失 - INA的天然气平台在海床上被发现 https://www.croatiaweek.com/inas-missing-gas-platform-found-on-seabed/)、2021年(0)。 英国：必须向RIDDOR报告危险事故 运营商应报告与以下相关的事故：\n坍塌：\u0026ldquo;任何海上设施或海上设施上任何设备的非故意坍塌或部分坍塌，这种坍塌危及设施的整体结构完整性\u0026rdquo;。\n海床下沉或坍塌：\u0026ldquo;任何可能影响海上设施基础或整体结构完整性的海床下沉或坍塌\u0026rdquo;。\n与监管机构的非正式讨论中，没有上述重大失效的记录。已发生一些失效，但未达到需要报告的程度，已知的很少。 IOGP 未报告，非正式反馈表明没有结构失效的情况。 美国：海上事故统计|安全和环境执法局（bsee.gov），监管机构收集海上事故数据 搜索2018年、2019年、2020年和2021年的重大事故，仅报告了各种起重机事故，未提及导管架失效，但注意到一些船舶撞击导致的支腿损坏。 澳大利亚：NOPSEMA 2019-2020年期间没有与结构（和井）完整性相关的监管行动。 参考规范 NORSOK N-005:2017+AC:2019 In-service integrity management of structures and marine systems DNV-RP-C210: Probabilistic methods for planning of inspection for fatigue cracks in offshore structures ","date":"2025-02-25T00:00:00Z","image":"https://whhong-research.github.io/p/%E6%8A%A5%E5%91%8A%E8%A7%A3%E8%AF%BB1structural-health-monitoring-by-use-of-sensor-data/image-20250225133412287_hu_cdd0d04472e4be19.png","permalink":"https://whhong-research.github.io/p/%E6%8A%A5%E5%91%8A%E8%A7%A3%E8%AF%BB1structural-health-monitoring-by-use-of-sensor-data/","title":"报告解读（1）：Structural health monitoring by use of sensor data"},{"content":"报告简介 The Guides for Operators, Scientists and Practicing Engineers on Quantifying the Value of Structural Health Information (SHI) for Decision Support have emerged from the scientific networking project COST Action TU1402 (www.cost-tu1402.eu) in the period from 2014 to 2019. The guides are the result of the TU1402 Working Group 5 on Standardisation in conjunction with the work of the Joint Committee on Structural Safety (JCSS – www.jcss.co).\n该项目有三份报告，分别是GUIDE for operators, GUIDE for practicing Engineers以及GUIDE for sicientists，三份报告在数学层面上以此递增。\n","date":"2025-02-25T00:00:00Z","image":"https://whhong-research.github.io/p/%E6%8A%A5%E5%91%8A%E8%A7%A3%E8%AF%BB2cost-tu1402-quantifying-the-value-of-shm/1_hu_eb4ae6eec401796a.png","permalink":"https://whhong-research.github.io/p/%E6%8A%A5%E5%91%8A%E8%A7%A3%E8%AF%BB2cost-tu1402-quantifying-the-value-of-shm/","title":"报告解读（2）：COST TU1402 Quantifying the Value of SHM"},{"content":"任务说明 在通过diffusion模型生成”无裂缝“图像后，使用SSIM生成重建图像与原始图像的差异图，希望作为粗糙的裂缝分割结果，能够生成较好的提示点，输出到SAM模型中进行精细化分割。需要处理的图像示例如下所示：\n为什么要考虑使用骨架化进行分析？\n当使用阈值分割时，将存在许多噪点，如图所示：\n同时，SAM模型中接受Mask和Point提示，Mask提示可以视为Dense的Point提示，思路为通过骨架化提取裂缝中的特征点，以便能够作为SAM模型中的Prompt进行精细化分割；\n实现代码 代码功能 将图片resize为（1024，512）大小，方便统一定义形态学去噪的kernel大小和连通域大小； 选取最暗的5%的像素点进行阈值分割，将最暗的5%的像素点视为“裂缝”; 进行形态学操作去除小噪点，并删除较小面积的连通域； 代码示例 阈值分割： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def adaptive_threshold1(self, image): image = cv2.resize(image, (1024,512)) if len(image.shape) \u0026gt; 2: gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) else: gray = image.copy() # 双边滤波保持边缘的同时去噪 smoothed = cv2.bilateralFilter(gray, d=15, sigmaColor=150, sigmaSpace=150) # 2. 将图像展平成1维数组 flat_img = smoothed.flatten() # 3. 计算阈值（最暗的5%像素） threshold = np.percentile(flat_img, 5) # 获取最暗的5%的阈值 # 4. 二值化处理 binary_img = np.zeros_like(smoothed) # 创建全黑背景 binary_img[smoothed \u0026lt;= threshold] = 255 # 最暗的5%像素设为白色 return binary_img 形态学操作： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def morphological_operations(self, binary): # 形态学操作去除小噪点 kernel = np.ones((1,1), np.uint8) opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel) # 连通域分析去除小区域 num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(opening) morphed = np.zeros_like(binary) # 保留大于最小面积的连通域 for i in range(1, num_labels): # 从1开始跳过背景 if stats[i, cv2.CC_STAT_AREA] \u0026gt;= self.min_area: morphed[labels == i] = 255 closed = cv2.morphologyEx(morphed, cv2.MORPH_CLOSE, kernel) return closed 骨架化： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def skeletonize(self, binary): # 确保输入是单通道二值图像 if len(binary.shape) \u0026gt; 2: binary = cv2.cvtColor(binary, cv2.COLOR_BGR2GRAY) # 骨架化 skeleton = skeletonize(binary) # 添加后处理步骤 skeleton = process_skeleton(skeleton) # 使用距离信息调整骨架宽度 skeleton = skeleton.astype(np.uint8) * 255 return skeleton 效果展示 相关函数功能介绍 cv2.distanceTransform 1 dst = cv2.distanceTransform(src, distanceType, maskSize[, dstType]) src: 输入图像，必须是单通道8位二值图像 distanceType: 距离类型 cv2.DIST_L1: 曼哈顿距离 cv2.DIST_L2: 欧氏距离 cv2.DIST_C: 切比雪夫距离 maskSize: 距离变换掩码大小 cv2.DIST_MASK_3: 3x3 掩码 cv2.DIST_MASK_5: 5x5 掩码 cv2.DIST_MASK_PRECISE: 更精确的算法 dstType: 输出图像类型（可选） cv2.CV_8U: 8位无符号整型 cv2.CV_32F: 32位浮点型 cv2.CV_64F: 64位浮点型 skimage.morphology.skeletonize skeletonize函数是scikit-image库中用于骨架化的函数，主要有三种方法:\n需要注意的是，需要保证输入图像是二值化图像，即只有0（黑色，背景）和255【或者表示为1】（白色，前景）；\nZhang-Suen细化算法(默认方法):\n基本思路：去除掉非骨架上的非0像素点； 如何查找非骨架点：对于非零像素点，考虑其8领域像素点 Step1: Step2:\n1 2 3 4 5 6 7 from skimage.morphology import skeletonize def zhang_suen_skeleton(binary): # 确保输入是二值图像 binary = binary.astype(bool) skeleton = skeletonize(binary) return skeleton.astype(np.uint8) * 255 LEE算法： 1 2 3 4 5 6 from skimage.morphology import skeletonize, lee def lee_skeleton(binary): binary = binary.astype(bool) skeleton = skeletonize(binary, method=\u0026#39;lee\u0026#39;) return skeleton.astype(np.uint8) * 255 基于距离变换的方法: 1 2 3 4 5 6 from skimage.morphology import medial_axis def medial_axis_skeleton(binary): # 返回骨架和距离变换 skeleton, distance = medial_axis(binary, return_distance=True) return skeleton.astype(np.uint8) * 255, distance ","date":"2025-02-24T16:46:00+08:00","image":"https://whhong-research.github.io/p/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861%E9%AA%A8%E6%9E%B6%E5%8C%96%E5%A4%84%E7%90%86%E8%A3%82%E7%BC%9D%E5%88%86%E5%89%B2%E6%8E%A9%E7%A0%81%E5%9B%BE%E5%83%8F/1_hu_83c1def872996799.png","permalink":"https://whhong-research.github.io/p/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861%E9%AA%A8%E6%9E%B6%E5%8C%96%E5%A4%84%E7%90%86%E8%A3%82%E7%BC%9D%E5%88%86%E5%89%B2%E6%8E%A9%E7%A0%81%E5%9B%BE%E5%83%8F/","title":"图像处理（1）：骨架化处理裂缝分割掩码图像"},{"content":"实验图像 添加负点来优化分割结果 当人工输入较为完美的裂缝提示点，且裂缝将图像分为明显两部分时，只输入正点可能导致SAM错误将大面积的一部分路面作为识别结果；此时，如果添加两个负点在掩码区域，将会出现较好识别裂缝的情况：\n猜想结论：正确少量的负点能很大程度优化sam的分割结果；\n正点的数量和分布影响 当正点未能较好地分布在裂缝上时，会出现裂缝边缘识别不全的情况，产生大量错误识别图案的情况：\n猜想结论：正点的覆盖区域尽量贴近裂缝形状\n正点和负点的比例影响 错误的正提示点影响 错误的负提示点影响 官网demo和github代码实现效果存在差异 https://github.com/facebookresearch/segment-anything/issues/762 https://github.com/facebookresearch/segment-anything/issues/620 https://github.com/facebookresearch/segment-anything/issues/169 负点的采样策略 随机采样 根据提示正点的轮廓进行采样 理想情况测试 ","date":"2025-02-24T16:46:00+08:00","image":"https://whhong-research.github.io/1.png","permalink":"https://whhong-research.github.io/p/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%862sam%E5%88%86%E5%89%B2%E8%A3%82%E7%BC%9D%E6%8F%90%E7%A4%BA%E7%82%B9%E7%AD%96%E7%95%A5/","title":"图像处理（2）：SAM分割裂缝提示点策略"},{"content":"个人总结 这篇文章提出了一种名为Crack-Diffusion的增强监督监测框架，用于分割路面裂缝。该框架主要分为两个阶段，第一阶段为无监督的multi-blur-based cold diffusion异常检测模型，第二阶段为有监督的U-NET分割模型。\n本博客主要关注于第一阶段的无监督过程，该阶段首先以无裂缝的图像作为训练集，用于训练diffusion模型，接着以有裂缝的图像作为输入，通过diffusion过程，生成“无裂缝”的图像，使用结构相似性指数来提取像素级的裂缝特征；\n关键假设： 将模糊的噪声应用在有裂缝和无裂缝的同一路面图像上，直至两张图像都不再有可见的裂缝特征时，二者的分布差异明显小于初始时的分布差异。\n基于扩散的无监督异常检测 扩散模型 定义： 扩散模型是图像生成和分辨率增强的一种方法，由扩散过程和逆扩散过程组成。扩散过程通过逐步将高斯噪声添加到原始图像数据中，将原始图像转化称为高斯分布的数据；而逆扩散过程通过不断删除添加的高斯噪声，将高斯分布的数据恢复成为原始图像。\n公式：公式（1）为扩散过程，公式（2）为逆扩散过程\n$$ x_t = \\sqrt{1-\\beta_t}x_{t-1} + \\sqrt{\\beta_t}Z_t\\tag{1}\\\\ $$ $$ x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{\\beta_t}{\\sqrt{1-\\alpha_t}}Z_t)\\tag{2} $$扩散模型和GAN模型对比 原理： 同一类型的高维数据（例如图片）往往会集中分布在低维空间中。\nGAN：裂缝通常被视为一种异常特征，GAN网络在处理这类问题时，是通过潜在张量（latent tensors）来重建异常图像，GAN通过学习正常路面样本的分布特征，当他遇到带裂缝的异常样本时，会尝试将其“拉回”正常样本的分布中，也就是将裂缝修复成正常路面的样子。\n扩散模型：扩散模型也是将原始图像转换成潜在变量，但扩散模型生成的潜在变量大小和原始图像的一样大，而GAN网络生成的潜在变量通常会小一些。\n直接应用常规扩散问题的挑战 路面裂缝特征是相对较小的物体，它们的像素与其他道路碎片（例如油漆，砾石和轮胎压痕）相似； 当diffusion模型经过良好训练时，会重建裂纹和碎屑像素，从而仍然产生包含裂缝信息的重建图像； 当diffusion模型训练不足时，无法准确地重建道路碎片；从而不能通过SSIM区分出碎屑和裂纹； 需求：重建图像中，裂缝区域被重建为无裂缝，道路碎屑、砾石等仍然保留； 多模糊冷扩散模型 退化算子 D 作用于给定的原始图像 x0 ，通过对 x0 添加 t 次噪声来实现扩散过程，可以表示为： $$ D(x_0, 0) = x_0, \\quad x_t = D(x_0,t)\\tag{3} $$ 退化算子 D 可以用来实现多种图像变换，例如：模糊，形变，像素化，噪声添加等，其中，退化程度由参数 t 的值决定\n该研究中，将2D高斯模糊和2D最大池化合并为退化算子D，2D高斯模糊使用（3，3）的卷积内核。在每个卷积期间，内核的权重计算出2D高斯分布，Max pooling作为高斯模糊的补充，退化算子D可以表示为： $$ D(x_t, 1, M) = x_{t+1}(i,j) = \\sum_{u=-r}^r\\sum_{v=-r}^r x_t(i+u,j+v)\\psi(u,v)f_{MaxPool}(u,v,M) $$ 实现代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 def noise_images(self, x, t, filtersize): # 正向扩散过程q xt = [] # 存储扩散后的图像 for batch in range(len(x)): # 遍历每个batch tem_x = x[batch] # 获取当前batch的图像 tem_t = np.max(t[batch]) # 获取当前batch的最大时间步 for i in range(tem_t): # 进行tem_t次扩散 tem_x1 = tem_x # 保存当前图像 tem_x = cv2.GaussianBlur(tem_x,(filtersize,filtersize),0,0) # 对图像进行高斯模糊 if (i==0) or (i%25==0): # 每25步或第一步进行一次最大池化 tem_x = max_pooling(tem_x,5) xt.append(tem_x) # 将扩散后的图像添加到结果列表 xt = np.array(xt) # 转换为numpy数组 return xt # 返回t时刻的噪声图像 关于cv2.GaussianBlur(src, ksize, sigmaX, sigmaY)函数，ksize表示高斯模糊核的大小，sigmaX和sigmaY设置为0时，OpenCV会自动计算标准差：σ = 0.3*((ksize-1)*0.5 - 1) + 0.8，对于3×3的核来说，标准差约为0.8，会产生轻微的模糊效果； 恢复算子 R 恢复算子 R 用于在添加噪声后恢复图像\n可以表示为： $R(x_t, t) \\approx x_0$​\n在获取潜在张量后，使用denoising扩散概率模型（DDPM）中的UNET结构作为恢复算子。恢复算子的结构如下图所示：\n实现Unet网络代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 class Unet(Model): def __init__(self, dim=64, # 基础维度 init_dim=None, # 初始维度 out_dim=None, # 输出维度 dim_mults=(1, 2, 4, 8), # 维度倍数 channels=3, # 输入图像通道数 resnet_block_groups=8, # ResNet块分组数 learned_variance=False, # 是否学习方差 sinusoidal_cond_mlp=True # 是否使用正弦位置编码 ): super(Unet, self).__init__() # 调用父类初始化 # 设置输入通道数 self.channels = channels # 如果没有指定初始维度,则设为基础维度的2/3 init_dim = default(init_dim, dim // 3 * 2) # 第一个卷积层,7x7卷积核 self.init_conv = nn.Conv2D(filters=init_dim, kernel_size=7, strides=1, padding=\u0026#39;SAME\u0026#39;) # 构建维度列表,使用dim_mults进行维度扩展 dims = [init_dim, *map(lambda m: dim * m, dim_mults)] # 将维度两两配对形成(输入维度,输出维度)的元组 in_out = list(zip(dims[:-1], dims[1:])) # 设置ResNet块类,使用指定的分组数 block_klass = partial(ResnetBlock, groups = resnet_block_groups) # 时间编码维度为基础维度的4倍 time_dim = dim * 4 self.sinusoidal_cond_mlp = sinusoidal_cond_mlp # 构建时间编码层 if sinusoidal_cond_mlp: # 使用正弦位置编码 self.time_mlp = Sequential([ SinusoidalPosEmb(dim), # 正弦位置编码 nn.Dense(units=time_dim), # 全连接层 GELU(), # GELU激活函数 nn.Dense(units=time_dim) # 全连接层 ]) else: # 使用普通MLP self.time_mlp = MLP(time_dim) # 下采样和上采样层列表 self.downs = [] self.ups = [] num_resolutions = len(in_out) # 构建下采样路径 for ind, (dim_in, dim_out) in enumerate(in_out): is_last = ind \u0026gt;= (num_resolutions - 1) # 是否为最后一层 self.downs.append([ block_klass(dim_in, dim_out, time_emb_dim=time_dim), # ResNet块1 block_klass(dim_out, dim_out, time_emb_dim=time_dim), # ResNet块2 Residual(PreNorm(dim_out, LinearAttention(dim_out))), # 线性注意力 Downsample(dim_out) if not is_last else Identity() # 下采样或恒等映射 ]) # 中间层 mid_dim = dims[-1] self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim) self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim))) self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim) # 构建上采样路径 for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])): is_last = ind \u0026gt;= (num_resolutions - 1) self.ups.append([ block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim), # ResNet块1 block_klass(dim_in, dim_in, time_emb_dim=time_dim), # ResNet块2 Residual(PreNorm(dim_in, LinearAttention(dim_in))), # 线性注意力 Upsample(dim_in) if not is_last else Identity() # 上采样或恒等映射 ]) # 设置输出维度 default_out_dim = channels * (1 if not learned_variance else 2) self.out_dim = default(out_dim, default_out_dim) # 最后的卷积层 self.final_conv = Sequential([ block_klass(dim * 2, dim), nn.Conv2D(filters=self.out_dim, kernel_size=1, strides=1) ]) def call(self, x, time=None, training=True, **kwargs): x = self.init_conv(x) # 初始卷积 t = self.time_mlp(time) # 时间编码 h = [] # 存储跳跃连接的特征 # 下采样路径 for block1, block2, attn, downsample in self.downs: x = block1(x, t) # ResNet块1 x = block2(x, t) # ResNet块2 x = attn(x) # 注意力层 h.append(x) # 保存特征用于跳跃连接 x = downsample(x) # 下采样 # 中间层处理 x = self.mid_block1(x, t) x = self.mid_attn(x) x = self.mid_block2(x, t) # 上采样路径 for block1, block2, attn, upsample in self.ups: x = tf.concat([x, h.pop()], axis=-1) # 拼接跳跃连接 x = block1(x, t) # ResNet块1 x = block2(x, t) # ResNet块2 x = attn(x) # 注意力层 x = upsample(x) # 上采样 # 最后的处理 x = tf.concat([x, h.pop()], axis=-1) # 最后的跳跃连接 x = self.final_conv(x) # 最后的卷积层 return x 损失函数 损失函数包括两个部分：\nL2距离：预测图像与真实图像之间的距离； SSIM：预测图像与真实图像之间的结构相似性度量； 完整的损失函数表达式： $Loss = \\lambda_1||x_0\u0026rsquo;(t) - x_0||_2 + \\lambda_2(1 - SSIM(x_0\u0026rsquo;(t), x_0))/2$\n其中：$\\lambda_1$ 和 $\\lambda_2$ 是两部分的权重系数\nSSIM的计算公式为：\n$SSIM(I_1,I_2) = \\frac{(2\\mu_1\\mu_2 + C_1)(2\\sigma_{12} + C_2)}{(\\mu_1^2 + \\mu_2^2 + C_1)(\\sigma_1^2 + \\sigma_2^2 + C_2)}$​\n$I_1$ 和 $I_2$ 是待比较的两张图像， $C_1$ 和 $C_2$ 是常数 $\\mu$ 表示图像的均值，$\\sigma$ 表示图像的标准差 使用3×3大小的滑动窗口计算 训练过程及测试过程 训练过程\n使用无裂缝的道路图像作为训练数据；\n对图像进行T轮多重模糊处理，得到图像xt ，完全消除裂缝特征；\n训练去噪U-Net来实现恢复算子R；\n训练过程中，参数t随机从区间(0, T]中采样；\n测试过程\n输入带裂缝的道路图像； 应用T次退化算子D； 使用训练好的去噪U-Net模型重建图像； 使用SSIM比较原始输入x₀与重建图像x₀\u0026rsquo;，用于生成裂缝分割结果； 模型效果及问题 某些情况下，基于SSIM的分割结果无法满足期望效果：\nSSIM不足以用于提取准确的裂缝特征信息，以案例2为例，人眼可以轻松识别出裂缝的位置，但是人眼不会注意到非裂缝区域的RGB值差异，但SSIM生成的差异图中，这些区域的差异强度可能与裂缝区域相当。\n作者还将提出的多模糊冷扩散模型与其他常见的无监督学习模型进行了对比，效果如下：\n可以看到，Multi-blur-based cold diffusion模型在四个数据集中的IoU都得到了最高值。\n代码复现结果 （working） 本章中大量代码来自于原文作者开源的Github仓库（https://github.com/ChengjiaHanSEU/CrackDiffusion）\n训练数据集 数据集链接：https://www.kaggle.com/datasets/arunrk7/surface-crack-detection\n数据集描述：数据集包含带有和没有裂纹的各种混凝土表面的图像。将图像数据分为两个分为负（无裂纹），在单独的文件夹中进行正面（带裂纹）进行图像分类。每个类别都有20000个图像，共有40000张图像，带有227 x 227像素，带有RGB通道。该数据集由Zhang等人（2016）提出的方法生成458个高分辨率图像（4032x3024像素）。高分辨率图像在表面饰面和照明条件方面发现具有很高的差异。没有应用随机旋转或翻转或倾斜的数据增强。\n使用了该数据集中的负类（即没有带有裂缝）的图像作为训练数据。\n试验1：使用MAE作为损失函数 1 2 3 4 5 6 with tf.GradientTape() as tape: t = diffusion.sample_timesteps(n=train_image.shape[0]) x_t = diffusion.noise_images(train_image, t, filtersize) predicted_noise_image = unet(x_t, t) loss = tf.keras.losses.mean_absolute_error(train_image, predicted_noise_image) # MAE loss loss = tf.reduce_mean(loss) 训练到122个epoch时触发早停，因为训练损失不断下降，而验证损失在过去30个epoch中上升了，最佳模型出现在92个epoch时刻； 测试效果：\n裂缝分割效果较好的： 裂缝分割效果较差的：（可能是由于裂缝过于细微） 基础知识 Latent Tensors(潜在张量):\n基本概念：\n潜在张量是深度学习中的一个重要概念，表示数据在\u0026quot;潜在空间\u0026quot;（latent space）中的表示形式\n它是原始数据经过编码（encoding）后的一种压缩表示\n通常维度比原始数据低，但包含了原始数据的关键特征信息\n特点：\n维度压缩：比如一张1024×1024的图片，可能被压缩成16×16×512的潜在张量（16×16表示空间维度被压缩，512为特征通道数，每个通道表示图像的不同特征或属性）\n信息提取：保留数据中最重要的特征，去除冗余信息\n连续性：在潜在空间中，相似的数据点会彼此靠近\n可解释性：潜在空间中的每个维度可能对应原始数据的某个特征\n工作原理举例（ 以图像处理为例）：\n输入：原始图像（如1024×1024×3的彩色图片）\n编码过程：通过神经网络将图像压缩成潜在张量\n潜在表示：可能是16×16×512的张量\n解码过程：可以从潜在张量重建出原始图像\n在不同模型中的应用：\nGAN中：生成器从随机潜在张量生成逼真的图像\nVAE中：将输入编码为潜在空间中的分布\n扩散模型中：通过逐步添加噪声形成潜在表示\nL2距离:\n定义：\nL2距离（L2 Distance）也称为欧几里得距离（Euclidean Distance），是最常用的距离度量方式之一。 在数学上表示为：$L2 = \\sqrt{\\sum_{i=1}^n (x_i - y_i)^2}$ 在不同维度的表现\n一维空间：两个数之间的绝对差值\n二维空间：平面上两点间的直线距离\n高维空间：各个维度差值的平方和开根号\n高斯模糊:\n基本概念：\n高斯模糊是一种使用高斯函数对图像进行平滑处理的技术。其核心是二维高斯函数：\n$G(x,y) = \\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2 + y^2}{2\\sigma^2}}$\n其中：\nσ 是标准差，控制模糊程度 x,y 是像素的坐标位置 关键参数：\n标准差(σ)\n控制模糊强度\nσ越大，模糊程度越高\nσ越小，模糊程度越低\n核大小(kernel size)\n通常为奇数（3×3, 5×5, 7×7等）\n建议核大小 ≥ 6σ + 1\n核越大，计算量越大\n冷扩散模型 vs 扩散模型\n冷扩散模型可以视为扩散模型的一种广义版本，不同点在于冷扩散模型中，扩散过程中的噪声不需要遵循高斯分布，可以选择Gaussian blur, snowflake noise, Gaussian mask等，在噪声的选择中具有灵活性。冷扩散模型中，扩散过程和逆扩散过程被建模为两个独立的算子，即退化算子D和恢复算子R。\n参考文献 Han, C., Yang, H., Ma, T., Wang, S., Zhao, C., Yang, Y., 2024. CrackDiffusion: A two-stage semantic segmentation framework for pavement crack combining unsupervised and supervised processes. Automation in Construction 160, 105332. https://doi.org/10.1016/j.autcon.2024.105332 https://github.com/ChengjiaHanSEU/CrackDiffusion ","date":"2025-02-24T00:00:00Z","image":"https://whhong-research.github.io/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/1_hu_a5bb19e252bdc3d5.png","permalink":"https://whhong-research.github.io/p/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/","title":"论文阅读（1）: CrackDiffusion: A two-stage semantic segmentation framework for pavement crack combining unsupervised and supervised processes"}]