[{"content":"任务说明 在通过diffusion模型生成”无裂缝“图像后，使用SSIM生成重建图像与原始图像的差异图，希望作为粗糙的裂缝分割结果，能够生成较好的提示点，输出到SAM模型中进行精细化分割。需要处理的图像示例如下所示：\n为什么要考虑使用骨架化进行分析？\n当使用阈值分割时，将存在许多噪点，如图所示：\n同时，SAM模型中接受Mask和Point提示，Mask提示可以视为Dense的Point提示，思路为通过骨架化提取裂缝中的特征点，以便能够作为SAM模型中的Prompt进行精细化分割；\n相关函数功能介绍 cv2.distanceTransform 1 dst = cv2.distanceTransform(src, distanceType, maskSize[, dstType]) src: 输入图像，必须是单通道8位二值图像 distanceType: 距离类型 cv2.DIST_L1: 曼哈顿距离 cv2.DIST_L2: 欧氏距离 cv2.DIST_C: 切比雪夫距离 maskSize: 距离变换掩码大小 cv2.DIST_MASK_3: 3x3 掩码 cv2.DIST_MASK_5: 5x5 掩码 cv2.DIST_MASK_PRECISE: 更精确的算法 dstType: 输出图像类型（可选） cv2.CV_8U: 8位无符号整型 cv2.CV_32F: 32位浮点型 cv2.CV_64F: 64位浮点型 skimage.morphology.skeletonize skeletonize函数是scikit-image库中用于骨架化的函数，主要有三种方法:\nZhang-Suen细化算法(默认方法): 1 2 3 4 5 6 7 from skimage.morphology import skeletonize def zhang_suen_skeleton(binary): # 确保输入是二值图像 binary = binary.astype(bool) skeleton = skeletonize(binary) return skeleton.astype(np.uint8) * 255 LEE算法： 1 2 3 4 5 6 from skimage.morphology import skeletonize, lee def lee_skeleton(binary): binary = binary.astype(bool) skeleton = skeletonize(binary, method=\u0026#39;lee\u0026#39;) return skeleton.astype(np.uint8) * 255 基于距离变换的方法: 1 2 3 4 5 6 from skimage.morphology import medial_axis def medial_axis_skeleton(binary): # 返回骨架和距离变换 skeleton, distance = medial_axis(binary, return_distance=True) return skeleton.astype(np.uint8) * 255, distance ","date":"2025-02-24T16:46:00+08:00","image":"https://whhong-research.github.io/p/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861%E9%AA%A8%E6%9E%B6%E5%8C%96%E5%A4%84%E7%90%86%E8%A3%82%E7%BC%9D%E5%88%86%E5%89%B2%E6%8E%A9%E7%A0%81%E5%9B%BE%E5%83%8F/1_hu_83c1def872996799.png","permalink":"https://whhong-research.github.io/p/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%861%E9%AA%A8%E6%9E%B6%E5%8C%96%E5%A4%84%E7%90%86%E8%A3%82%E7%BC%9D%E5%88%86%E5%89%B2%E6%8E%A9%E7%A0%81%E5%9B%BE%E5%83%8F/","title":"图像处理（1）：骨架化处理裂缝分割掩码图像"},{"content":"个人总结 这篇文章提出了一种名为Crack-Diffusion的增强监督监测框架，用于分割路面裂缝。该框架主要分为两个阶段，第一阶段为无监督的multi-blur-based cold diffusion异常检测模型，第二阶段为有监督的U-NET分割模型。\n本博客主要关注于第一阶段的无监督过程，该阶段首先以无裂缝的图像作为训练集，用于训练diffusion模型，接着以有裂缝的图像作为输入，通过diffusion过程，生成“无裂缝”的图像，使用结构相似性指数来提取像素级的裂缝特征；\n关键假设： 将模糊的噪声应用在有裂缝和无裂缝的同一路面图像上，直至两张图像都不再有可见的裂缝特征时，二者的分布差异明显小于初始时的分布差异。\n基于扩散的无监督异常检测 扩散模型 定义： 扩散模型是图像生成和分辨率增强的一种方法，由扩散过程和逆扩散过程组成。扩散过程通过逐步将高斯噪声添加到原始图像数据中，将原始图像转化称为高斯分布的数据；而逆扩散过程通过不断删除添加的高斯噪声，将高斯分布的数据恢复成为原始图像。\n公式：公式（1）为扩散过程，公式（2）为逆扩散过程\n$$ x_t = \\sqrt{1-\\beta_t}x_{t-1} + \\sqrt{\\beta_t}Z_t\\tag{1}\\\\ $$ $$ x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{\\beta_t}{\\sqrt{1-\\alpha_t}}Z_t)\\tag{2} $$扩散模型和GAN模型对比 原理： 同一类型的高维数据（例如图片）往往会集中分布在低维空间中。\nGAN：裂缝通常被视为一种异常特征，GAN网络在处理这类问题时，是通过潜在张量（latent tensors）来重建异常图像，GAN通过学习正常路面样本的分布特征，当他遇到带裂缝的异常样本时，会尝试将其“拉回”正常样本的分布中，也就是将裂缝修复成正常路面的样子。\n扩散模型：扩散模型也是将原始图像转换成潜在变量，但扩散模型生成的潜在变量大小和原始图像的一样大，而GAN网络生成的潜在变量通常会小一些。\n直接应用常规扩散问题的挑战 路面裂缝特征是相对较小的物体，它们的像素与其他道路碎片（例如油漆，砾石和轮胎压痕）相似； 当diffusion模型经过良好训练时，会重建裂纹和碎屑像素，从而仍然产生包含裂缝信息的重建图像； 当diffusion模型训练不足时，无法准确地重建道路碎片；从而不能通过SSIM区分出碎屑和裂纹； 需求：重建图像中，裂缝区域被重建为无裂缝，道路碎屑、砾石等仍然保留； 多模糊冷扩散模型 退化算子 D 作用于给定的原始图像 x0 ，通过对 x0 添加 t 次噪声来实现扩散过程，可以表示为： $$ D(x_0, 0) = x_0, \\quad x_t = D(x_0,t)\\tag{3} $$ 退化算子 D 可以用来实现多种图像变换，例如：模糊，形变，像素化，噪声添加等，其中，退化程度由参数 t 的值决定\n该研究中，将2D高斯模糊和2D最大池化合并为退化算子D，2D高斯模糊使用（3，3）的卷积内核。在每个卷积期间，内核的权重计算出2D高斯分布，Max pooling作为高斯模糊的补充，退化算子D可以表示为： $$ D(x_t, 1, M) = x_{t+1}(i,j) = \\sum_{u=-r}^r\\sum_{v=-r}^r x_t(i+u,j+v)\\psi(u,v)f_{MaxPool}(u,v,M) $$ 实现代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 def noise_images(self, x, t, filtersize): # 正向扩散过程q xt = [] # 存储扩散后的图像 for batch in range(len(x)): # 遍历每个batch tem_x = x[batch] # 获取当前batch的图像 tem_t = np.max(t[batch]) # 获取当前batch的最大时间步 for i in range(tem_t): # 进行tem_t次扩散 tem_x1 = tem_x # 保存当前图像 tem_x = cv2.GaussianBlur(tem_x,(filtersize,filtersize),0,0) # 对图像进行高斯模糊 if (i==0) or (i%25==0): # 每25步或第一步进行一次最大池化 tem_x = max_pooling(tem_x,5) xt.append(tem_x) # 将扩散后的图像添加到结果列表 xt = np.array(xt) # 转换为numpy数组 return xt # 返回t时刻的噪声图像 关于cv2.GaussianBlur(src, ksize, sigmaX, sigmaY)函数，ksize表示高斯模糊核的大小，sigmaX和sigmaY设置为0时，OpenCV会自动计算标准差：σ = 0.3*((ksize-1)*0.5 - 1) + 0.8，对于3×3的核来说，标准差约为0.8，会产生轻微的模糊效果； 恢复算子 R 恢复算子 R 用于在添加噪声后恢复图像\n可以表示为： $R(x_t, t) \\approx x_0$​\n在获取潜在张量后，使用denoising扩散概率模型（DDPM）中的UNET结构作为恢复算子。恢复算子的结构如下图所示：\n实现Unet网络代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 class Unet(Model): def __init__(self, dim=64, # 基础维度 init_dim=None, # 初始维度 out_dim=None, # 输出维度 dim_mults=(1, 2, 4, 8), # 维度倍数 channels=3, # 输入图像通道数 resnet_block_groups=8, # ResNet块分组数 learned_variance=False, # 是否学习方差 sinusoidal_cond_mlp=True # 是否使用正弦位置编码 ): super(Unet, self).__init__() # 调用父类初始化 # 设置输入通道数 self.channels = channels # 如果没有指定初始维度,则设为基础维度的2/3 init_dim = default(init_dim, dim // 3 * 2) # 第一个卷积层,7x7卷积核 self.init_conv = nn.Conv2D(filters=init_dim, kernel_size=7, strides=1, padding=\u0026#39;SAME\u0026#39;) # 构建维度列表,使用dim_mults进行维度扩展 dims = [init_dim, *map(lambda m: dim * m, dim_mults)] # 将维度两两配对形成(输入维度,输出维度)的元组 in_out = list(zip(dims[:-1], dims[1:])) # 设置ResNet块类,使用指定的分组数 block_klass = partial(ResnetBlock, groups = resnet_block_groups) # 时间编码维度为基础维度的4倍 time_dim = dim * 4 self.sinusoidal_cond_mlp = sinusoidal_cond_mlp # 构建时间编码层 if sinusoidal_cond_mlp: # 使用正弦位置编码 self.time_mlp = Sequential([ SinusoidalPosEmb(dim), # 正弦位置编码 nn.Dense(units=time_dim), # 全连接层 GELU(), # GELU激活函数 nn.Dense(units=time_dim) # 全连接层 ]) else: # 使用普通MLP self.time_mlp = MLP(time_dim) # 下采样和上采样层列表 self.downs = [] self.ups = [] num_resolutions = len(in_out) # 构建下采样路径 for ind, (dim_in, dim_out) in enumerate(in_out): is_last = ind \u0026gt;= (num_resolutions - 1) # 是否为最后一层 self.downs.append([ block_klass(dim_in, dim_out, time_emb_dim=time_dim), # ResNet块1 block_klass(dim_out, dim_out, time_emb_dim=time_dim), # ResNet块2 Residual(PreNorm(dim_out, LinearAttention(dim_out))), # 线性注意力 Downsample(dim_out) if not is_last else Identity() # 下采样或恒等映射 ]) # 中间层 mid_dim = dims[-1] self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim) self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim))) self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim) # 构建上采样路径 for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])): is_last = ind \u0026gt;= (num_resolutions - 1) self.ups.append([ block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim), # ResNet块1 block_klass(dim_in, dim_in, time_emb_dim=time_dim), # ResNet块2 Residual(PreNorm(dim_in, LinearAttention(dim_in))), # 线性注意力 Upsample(dim_in) if not is_last else Identity() # 上采样或恒等映射 ]) # 设置输出维度 default_out_dim = channels * (1 if not learned_variance else 2) self.out_dim = default(out_dim, default_out_dim) # 最后的卷积层 self.final_conv = Sequential([ block_klass(dim * 2, dim), nn.Conv2D(filters=self.out_dim, kernel_size=1, strides=1) ]) def call(self, x, time=None, training=True, **kwargs): x = self.init_conv(x) # 初始卷积 t = self.time_mlp(time) # 时间编码 h = [] # 存储跳跃连接的特征 # 下采样路径 for block1, block2, attn, downsample in self.downs: x = block1(x, t) # ResNet块1 x = block2(x, t) # ResNet块2 x = attn(x) # 注意力层 h.append(x) # 保存特征用于跳跃连接 x = downsample(x) # 下采样 # 中间层处理 x = self.mid_block1(x, t) x = self.mid_attn(x) x = self.mid_block2(x, t) # 上采样路径 for block1, block2, attn, upsample in self.ups: x = tf.concat([x, h.pop()], axis=-1) # 拼接跳跃连接 x = block1(x, t) # ResNet块1 x = block2(x, t) # ResNet块2 x = attn(x) # 注意力层 x = upsample(x) # 上采样 # 最后的处理 x = tf.concat([x, h.pop()], axis=-1) # 最后的跳跃连接 x = self.final_conv(x) # 最后的卷积层 return x 损失函数 损失函数包括两个部分：\nL2距离：预测图像与真实图像之间的距离； SSIM：预测图像与真实图像之间的结构相似性度量； 完整的损失函数表达式： $Loss = \\lambda_1||x_0\u0026rsquo;(t) - x_0||_2 + \\lambda_2(1 - SSIM(x_0\u0026rsquo;(t), x_0))/2$\n其中：$\\lambda_1$ 和 $\\lambda_2$ 是两部分的权重系数\nSSIM的计算公式为：\n$SSIM(I_1,I_2) = \\frac{(2\\mu_1\\mu_2 + C_1)(2\\sigma_{12} + C_2)}{(\\mu_1^2 + \\mu_2^2 + C_1)(\\sigma_1^2 + \\sigma_2^2 + C_2)}$​\n$I_1$ 和 $I_2$ 是待比较的两张图像， $C_1$ 和 $C_2$ 是常数 $\\mu$ 表示图像的均值，$\\sigma$ 表示图像的标准差 使用3×3大小的滑动窗口计算 训练过程及测试过程 训练过程\n使用无裂缝的道路图像作为训练数据；\n对图像进行T轮多重模糊处理，得到图像xt ，完全消除裂缝特征；\n训练去噪U-Net来实现恢复算子R；\n训练过程中，参数t随机从区间(0, T]中采样；\n测试过程\n输入带裂缝的道路图像； 应用T次退化算子D； 使用训练好的去噪U-Net模型重建图像； 使用SSIM比较原始输入x₀与重建图像x₀\u0026rsquo;，用于生成裂缝分割结果； 模型效果及问题 某些情况下，基于SSIM的分割结果无法满足期望效果：\nSSIM不足以用于提取准确的裂缝特征信息，以案例2为例，人眼可以轻松识别出裂缝的位置，但是人眼不会注意到非裂缝区域的RGB值差异，但SSIM生成的差异图中，这些区域的差异强度可能与裂缝区域相当。\n作者还将提出的多模糊冷扩散模型与其他常见的无监督学习模型进行了对比，效果如下：\n可以看到，Multi-blur-based cold diffusion模型在四个数据集中的IoU都得到了最高值。\n代码复现结果 （working） 本章中大量代码来自于原文作者开源的Github仓库（https://github.com/ChengjiaHanSEU/CrackDiffusion）\n训练数据集 数据集链接：https://www.kaggle.com/datasets/arunrk7/surface-crack-detection\n数据集描述：数据集包含带有和没有裂纹的各种混凝土表面的图像。将图像数据分为两个分为负（无裂纹），在单独的文件夹中进行正面（带裂纹）进行图像分类。每个类别都有20000个图像，共有40000张图像，带有227 x 227像素，带有RGB通道。该数据集由Zhang等人（2016）提出的方法生成458个高分辨率图像（4032x3024像素）。高分辨率图像在表面饰面和照明条件方面发现具有很高的差异。没有应用随机旋转或翻转或倾斜的数据增强。\n使用了该数据集中的负类（即没有带有裂缝）的图像作为训练数据。\n试验1：使用MAE作为损失函数 1 2 3 4 5 6 with tf.GradientTape() as tape: t = diffusion.sample_timesteps(n=train_image.shape[0]) x_t = diffusion.noise_images(train_image, t, filtersize) predicted_noise_image = unet(x_t, t) loss = tf.keras.losses.mean_absolute_error(train_image, predicted_noise_image) # MAE loss loss = tf.reduce_mean(loss) 训练到122个epoch时触发早停，因为训练损失不断下降，而验证损失在过去30个epoch中上升了，最佳模型出现在92个epoch时刻； 测试效果：\n裂缝分割效果较好的： 裂缝分割效果较差的：（可能是由于裂缝过于细微） 基础知识 Latent Tensors(潜在张量):\n基本概念：\n潜在张量是深度学习中的一个重要概念，表示数据在\u0026quot;潜在空间\u0026quot;（latent space）中的表示形式\n它是原始数据经过编码（encoding）后的一种压缩表示\n通常维度比原始数据低，但包含了原始数据的关键特征信息\n特点：\n维度压缩：比如一张1024×1024的图片，可能被压缩成16×16×512的潜在张量（16×16表示空间维度被压缩，512为特征通道数，每个通道表示图像的不同特征或属性）\n信息提取：保留数据中最重要的特征，去除冗余信息\n连续性：在潜在空间中，相似的数据点会彼此靠近\n可解释性：潜在空间中的每个维度可能对应原始数据的某个特征\n工作原理举例（ 以图像处理为例）：\n输入：原始图像（如1024×1024×3的彩色图片）\n编码过程：通过神经网络将图像压缩成潜在张量\n潜在表示：可能是16×16×512的张量\n解码过程：可以从潜在张量重建出原始图像\n在不同模型中的应用：\nGAN中：生成器从随机潜在张量生成逼真的图像\nVAE中：将输入编码为潜在空间中的分布\n扩散模型中：通过逐步添加噪声形成潜在表示\nL2距离:\n定义：\nL2距离（L2 Distance）也称为欧几里得距离（Euclidean Distance），是最常用的距离度量方式之一。 在数学上表示为：$L2 = \\sqrt{\\sum_{i=1}^n (x_i - y_i)^2}$ 在不同维度的表现\n一维空间：两个数之间的绝对差值\n二维空间：平面上两点间的直线距离\n高维空间：各个维度差值的平方和开根号\n高斯模糊:\n基本概念：\n高斯模糊是一种使用高斯函数对图像进行平滑处理的技术。其核心是二维高斯函数：\n$G(x,y) = \\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2 + y^2}{2\\sigma^2}}$\n其中：\nσ 是标准差，控制模糊程度 x,y 是像素的坐标位置 关键参数：\n标准差(σ)\n控制模糊强度\nσ越大，模糊程度越高\nσ越小，模糊程度越低\n核大小(kernel size)\n通常为奇数（3×3, 5×5, 7×7等）\n建议核大小 ≥ 6σ + 1\n核越大，计算量越大\n冷扩散模型 vs 扩散模型\n冷扩散模型可以视为扩散模型的一种广义版本，不同点在于冷扩散模型中，扩散过程中的噪声不需要遵循高斯分布，可以选择Gaussian blur, snowflake noise, Gaussian mask等，在噪声的选择中具有灵活性。冷扩散模型中，扩散过程和逆扩散过程被建模为两个独立的算子，即退化算子D和恢复算子R。\n参考文献 Han, C., Yang, H., Ma, T., Wang, S., Zhao, C., Yang, Y., 2024. CrackDiffusion: A two-stage semantic segmentation framework for pavement crack combining unsupervised and supervised processes. Automation in Construction 160, 105332. https://doi.org/10.1016/j.autcon.2024.105332 https://github.com/ChengjiaHanSEU/CrackDiffusion ","date":"2025-02-24T00:00:00Z","image":"https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/1_hu_a5bb19e252bdc3d5.png","permalink":"https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/","title":"Paper Reading 1: CrackDiffusion: A two-stage semantic segmentation framework for pavement crack combining unsupervised and supervised processes"}]