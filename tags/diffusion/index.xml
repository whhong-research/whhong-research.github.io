<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Diffusion on whhong的博客</title>
        <link>https://whhong-research.github.io/tags/diffusion/</link>
        <description>Recent content in Diffusion on whhong的博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>whhong</copyright>
        <lastBuildDate>Fri, 21 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://whhong-research.github.io/tags/diffusion/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Paper Reading 1: CrackDiffusion: A two-stage semantic segmentation framework for pavement crack combining unsupervised and supervised processes</title>
        <link>https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/</link>
        <pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate>
        
        <guid>https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/</guid>
        <description>&lt;img src="https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/PaperReading1.png" alt="Featured image of post Paper Reading 1: CrackDiffusion: A two-stage semantic segmentation framework for pavement crack combining unsupervised and supervised processes" /&gt;&lt;h1 id=&#34;个人总结&#34;&gt;个人总结
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;这篇文章提出了一种名为Crack-Diffusion的增强监督监测框架，用于分割路面裂缝。该框架主要分为两个阶段，第一阶段为无监督的multi-blur-based cold diffusion异常检测模型，第二阶段为有监督的U-NET分割模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;本博客主要关注于第一阶段的无监督过程，该阶段首先以无裂缝的图像作为训练集，用于训练diffusion模型，接着以有裂缝的图像作为输入，通过diffusion过程，生成“无裂缝”的图像，使用结构相似性指数来提取像素级的裂缝特征；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键假设&lt;/strong&gt;： 将模糊的噪声应用在有裂缝和无裂缝的同一路面图像上，直至两张图像都不再有可见的裂缝特征时，二者的分布差异明显小于初始时的分布差异。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;基础知识&#34;&gt;基础知识
&lt;/h1&gt;&lt;h2 id=&#34;latent-tensors潜在张量&#34;&gt;Latent Tensors(潜在张量)
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;基本概念&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;潜在张量是深度学习中的一个重要概念，表示数据在&amp;quot;潜在空间&amp;quot;（latent space）中的表示形式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;它是原始数据经过编码（encoding）后的一种压缩表示&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通常维度比原始数据低，但包含了原始数据的关键特征信息&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;特点&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;维度压缩&lt;/strong&gt;：比如一张1024×1024的图片，可能被压缩成16×16×512的潜在张量（16×16表示空间维度被压缩，512为特征通道数，每个通道表示图像的不同特征或属性）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;信息提取&lt;/strong&gt;：保留数据中最重要的特征，去除冗余信息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;连续性&lt;/strong&gt;：在潜在空间中，相似的数据点会彼此靠近&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;可解释性&lt;/strong&gt;：潜在空间中的每个维度可能对应原始数据的某个特征&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;工作原理举例&lt;/strong&gt;（ 以图像处理为例）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;输入&lt;/strong&gt;：原始图像（如1024×1024×3的彩色图片）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;编码过程&lt;/strong&gt;：通过神经网络将图像压缩成潜在张量&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;潜在表示&lt;/strong&gt;：可能是16×16×512的张量&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;解码过程&lt;/strong&gt;：可以从潜在张量重建出原始图像&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;在不同模型中的应用&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GAN中&lt;/strong&gt;：生成器从随机潜在张量生成逼真的图像&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;VAE中&lt;/strong&gt;：将输入编码为潜在空间中的分布&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;扩散模型中&lt;/strong&gt;：通过逐步添加噪声形成潜在表示&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;l2距离&#34;&gt;L2距离
&lt;/h2&gt;&lt;p&gt;L2距离（L2 Distance）也称为欧几里得距离（Euclidean Distance），是最常用的距离度量方式之一。让我详细解释：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;基本定义&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;L2距离是两点之间的直线距离&lt;/li&gt;
&lt;li&gt;在数学上表示为：$L2 = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}$&lt;/li&gt;
&lt;li&gt;L2范数（norm）是向量到原点的欧几里得距离&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在不同维度的表现&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;一维空间&lt;/strong&gt;：两个数之间的绝对差值&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;二维空间&lt;/strong&gt;：平面上两点间的直线距离&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高维空间&lt;/strong&gt;：各个维度差值的平方和开根号&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;高斯模糊&#34;&gt;高斯模糊
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;基本概念&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;高斯模糊是一种使用高斯函数对图像进行平滑处理的技术。其核心是二维高斯函数：&lt;/p&gt;
&lt;p&gt;$G(x,y) = \frac{1}{2\pi\sigma^2}e^{-\frac{x^2 + y^2}{2\sigma^2}}$&lt;/p&gt;
&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;σ 是标准差，控制模糊程度&lt;/li&gt;
&lt;li&gt;x,y 是像素的坐标位置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;关键参数&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;标准差(σ)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;控制模糊强度&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;σ越大，模糊程度越高&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;σ越小，模糊程度越低&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;核大小(kernel size)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;通常为奇数（3×3, 5×5, 7×7等）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;建议核大小 ≥ 6σ + 1&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;核越大，计算量越大&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;基于扩散的无监督异常检测&#34;&gt;基于扩散的无监督异常检测
&lt;/h1&gt;&lt;h2 id=&#34;扩散模型&#34;&gt;扩散模型
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;定义&lt;/strong&gt;： 扩散模型是图像生成和分辨率增强的一种方法，由扩散过程和逆扩散过程组成。扩散过程通过逐步将高斯噪声添加到原始图像数据中，将原始图像转化称为高斯分布的数据；而逆扩散过程通过不断删除添加的高斯噪声，将高斯分布的数据恢复成为原始图像。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;公式&lt;/strong&gt;：公式（1）为扩散过程，公式（2）为逆扩散过程&lt;/p&gt;
$$
   x_t = \sqrt{1-\beta_t}x_{t-1} + \sqrt{\beta_t}Z_t\tag{1}\\
   $$&lt;/li&gt;
&lt;/ol&gt;
$$
x_{t-1} = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{\beta_t}{\sqrt{1-\alpha_t}}Z_t)\tag{2}
$$&lt;h2 id=&#34;扩散模型和gan模型对比&#34;&gt;扩散模型和GAN模型对比
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;： 同一类型的高维数据（例如图片）往往会集中分布在低维空间中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GAN&lt;/strong&gt;：裂缝通常被视为一种异常特征，GAN网络在处理这类问题时，是通过潜在张量（latent tensors）来重建异常图像，GAN通过学习正常路面样本的分布特征，当他遇到带裂缝的异常样本时，会尝试将其“拉回”正常样本的分布中，也就是将裂缝修复成正常路面的样子。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;扩散模型&lt;/strong&gt;：扩散模型也是将原始图像转换成潜在变量，但扩散模型生成的潜在变量大小和原始图像的一样大，而GAN网络生成的潜在变量通常会小一些。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/image-20250224115126966.png&#34;
	width=&#34;476&#34;
	height=&#34;295&#34;
	srcset=&#34;https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/image-20250224115126966_hu_9d375cbef6809b2f.png 480w, https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/image-20250224115126966_hu_26d8554963e0620c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;潜在变量（latent tensors）在GAN网络和Diffusion模型中的对比&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;161&#34;
		data-flex-basis=&#34;387px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;直接应用常规扩散问题的挑战&#34;&gt;直接应用常规扩散问题的挑战
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;路面裂缝特征是相对较小的物体，它们的像素与其他道路碎片（例如油漆，砾石和轮胎压痕）相似；&lt;/li&gt;
&lt;li&gt;当diffusion模型经过良好训练时，会重建裂纹和碎屑像素，从而仍然产生包含裂缝信息的重建图像；&lt;/li&gt;
&lt;li&gt;当diffusion模型训练不足时，无法准确地重建道路碎片；从而不能通过SSIM区分出碎屑和裂纹；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;需求&lt;/strong&gt;：重建图像中，裂缝区域被重建为无裂缝，道路碎屑、砾石等仍然保留；&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;多模糊冷扩散模型&#34;&gt;多模糊冷扩散模型
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/image-20250224124120609.png&#34;
	width=&#34;919&#34;
	height=&#34;716&#34;
	srcset=&#34;https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/image-20250224124120609_hu_e16cb66f332ddaf1.png 480w, https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/image-20250224124120609_hu_d0bea3fea956c012.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;多模糊冷扩散模型的裂缝检测过程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;128&#34;
		data-flex-basis=&#34;308px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;冷扩散模型-vs-扩散模型&#34;&gt;冷扩散模型 vs 扩散模型
&lt;/h3&gt;&lt;p&gt;冷扩散模型可以视为扩散模型的一种广义版本，不同点在于冷扩散模型中，扩散过程中的噪声不需要遵循高斯分布，可以选择Gaussian blur, snowflake noise, Gaussian mask等，在噪声的选择中具有灵活性。冷扩散模型中，扩散过程和逆扩散过程被建模为两个独立的算子，即&lt;strong&gt;退化算子D&lt;/strong&gt;和&lt;strong&gt;恢复算子R&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;退化算子-d&#34;&gt;退化算子 D
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;作用于给定的原始图像 x&lt;del&gt;0&lt;/del&gt; ，通过对 x&lt;del&gt;0&lt;/del&gt; 添加 t 次噪声来实现扩散过程，可以表示为：&lt;/li&gt;
&lt;/ul&gt;
$$
D(x_0, 0) = x_0, \quad x_t = D(x_0,t)\tag{3}
$$&lt;p&gt;
退化算子 D 可以用来实现多种图像变换，例如：模糊，形变，像素化，噪声添加等，其中，退化程度由参数 t 的值决定&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;该研究中，将2D高斯模糊和2D最大池化合并为&lt;strong&gt;退化算子D&lt;/strong&gt;，2D高斯模糊使用（3，3）的卷积内核。在每个卷积期间，内核的权重计算出2D高斯分布，Max pooling作为高斯模糊的补充，&lt;strong&gt;退化算子D&lt;/strong&gt;可以表示为：&lt;/li&gt;
&lt;/ul&gt;
$$
D(x_t, 1, M) = x_{t+1}(i,j) = \sum_{u=-r}^r\sum_{v=-r}^r x_t(i+u,j+v)\psi(u,v)f_{MaxPool}(u,v,M)
$$&lt;h3 id=&#34;恢复算子-r&#34;&gt;恢复算子 R
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;恢复算子 R 用于在添加噪声后恢复图像&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可以表示为： $R(x_t, t) \approx x_0$​&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在获取潜在张量后，使用denoising扩散概率模型（DDPM）中的UNET结构作为恢复算子。恢复算子的结构如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/image-20250224115858087.png&#34;
	width=&#34;974&#34;
	height=&#34;429&#34;
	srcset=&#34;https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/image-20250224115858087_hu_9a263ff10b108b4d.png 480w, https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/image-20250224115858087_hu_373b7bbe0c2bcc74.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;多模糊冷扩散模型中的恢复算子R&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;227&#34;
		data-flex-basis=&#34;544px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;损失函数&#34;&gt;损失函数
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;损失函数包括两个部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L2距离：预测图像与真实图像之间的距离；&lt;/li&gt;
&lt;li&gt;SSIM：预测图像与真实图像之间的结构相似性度量；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;完整的损失函数表达式：
$Loss = \lambda_1||x_0&amp;rsquo;(t) - x_0||_2 + \lambda_2(1 - SSIM(x_0&amp;rsquo;(t), x_0))/2$&lt;/p&gt;
&lt;p&gt;其中：$\lambda_1$ 和 $\lambda_2$ 是两部分的权重系数&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SSIM的计算公式为：&lt;/p&gt;
&lt;p&gt;$SSIM(I_1,I_2) = \frac{(2\mu_1\mu_2 + C_1)(2\sigma_{12} + C_2)}{(\mu_1^2 + \mu_2^2 + C_1)(\sigma_1^2 + \sigma_2^2 + C_2)}$​&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$I_1$ 和 $I_2$ 是待比较的两张图像，&lt;/li&gt;
&lt;li&gt;$C_1$ 和 $C_2$ 是常数&lt;/li&gt;
&lt;li&gt;$\mu$ 表示图像的均值，$\sigma$ 表示图像的标准差&lt;/li&gt;
&lt;li&gt;使用3×3大小的滑动窗口计算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;训练过程&#34;&gt;训练过程
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;使用无裂缝的道路图像作为训练数据；&lt;/li&gt;
&lt;li&gt;对图像进行T轮多重模糊处理，得到图像x&lt;del&gt;t&lt;/del&gt; ，完全消除裂缝特征；&lt;/li&gt;
&lt;li&gt;训练去噪U-Net来实现恢复算子R；&lt;/li&gt;
&lt;li&gt;训练过程中，参数t随机从区间(0, T]中采样；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;测试过程&#34;&gt;测试过程
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;输入带裂缝的道路图像；&lt;/li&gt;
&lt;li&gt;应用T次退化算子D；&lt;/li&gt;
&lt;li&gt;使用训练好的去噪U-Net模型重建图像；&lt;/li&gt;
&lt;li&gt;使用SSIM比较原始输入x₀与重建图像x₀&amp;rsquo;，用于生成裂缝分割结果；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;模型效果及问题&#34;&gt;模型效果及问题
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;某些情况下，基于SSIM的分割结果无法满足期望效果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/image-20250224131456761.png&#34;
	width=&#34;915&#34;
	height=&#34;574&#34;
	srcset=&#34;https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/image-20250224131456761_hu_9f1eb73484bb27ed.png 480w, https://whhong-research.github.io/p/paper-reading-1-crackdiffusion-a-two-stage-semantic-segmentation-framework-for-pavement-crack-combining-unsupervised-and-supervised-processes/image-20250224131456761_hu_30487711f2c0da94.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;基于SSIM分割效果对比，案例1中背景分布与训练图片相近，案例2中背景分布与训练图片差异较大&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;159&#34;
		data-flex-basis=&#34;382px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SSIM不足以用于提取准确的裂缝特征信息，以案例2为例，人眼可以轻松识别出裂缝的位置，但是人眼不会注意到非裂缝区域的RGB值差异，但SSIM生成的差异图中，这些区域的差异强度可能与裂缝区域相当。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;代码复现-working&#34;&gt;代码复现 （working）
&lt;/h2&gt;&lt;p&gt;本章中大量代码来自于原文作者开源的Github仓库（https://github.com/ChengjiaHanSEU/CrackDiffusion）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h1 id=&#34;参考文献&#34;&gt;参考文献
&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;Han, C., Yang, H., Ma, T., Wang, S., Zhao, C., Yang, Y., 2024. CrackDiffusion: A two-stage semantic segmentation framework for pavement crack combining unsupervised and supervised processes. Automation in Construction 160, 105332. &lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1016/j.autcon.2024.105332&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.1016/j.autcon.2024.105332&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/ChengjiaHanSEU/CrackDiffusion&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/ChengjiaHanSEU/CrackDiffusion&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        
    </channel>
</rss>
